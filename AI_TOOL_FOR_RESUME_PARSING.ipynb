{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwvXh2IojuYHvQa65WQPh+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alloysArtifexLabs/IMAGE-AI/blob/image-classifier/AI_TOOL_FOR_RESUME_PARSING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UonC5LWdTTW2",
        "outputId": "04625331-1120-4303-bdad-3734b7e9c160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20240706\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy tensorflow pdfminer.six\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtKDOUjkTt-X",
        "outputId": "183f2897-34e5-4f83-b4bb-f0e71f881156"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('sample_resumes', exist_ok=True)"
      ],
      "metadata": {
        "id": "0pUXmtzWwAn8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4JyprNK5w3pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "5U9lD8EuwTlo",
        "outputId": "1ac05b91-6180-4ded-c8dc-6ad16af26f00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-04ac44e8-eaeb-40f2-b523-c39dd2211a83\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-04ac44e8-eaeb-40f2-b523-c39dd2211a83\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Alloys Product Solution Engineer Resume.pdf to Alloys Product Solution Engineer Resume.pdf\n",
            "Saving Alloys Support Engineer Resume.pdf to Alloys Support Engineer Resume.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in the 'sample_resumes' directory\n",
        "resume_dir = 'sample_resumes'\n",
        "files = os.listdir(resume_dir)\n",
        "print(\"Files in 'sample_resumes':\", files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR2WX7DNw5XF",
        "outputId": "240d9de8-32e3-4b01-ee82-d76745b14774"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in 'sample_resumes': []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "all_files = os.listdir()\n",
        "print(\"Files in the current directory:\", all_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFJO8eazxPsi",
        "outputId": "562751cf-e49e-4d29-cd15-979e16d42564"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the current directory: ['.config', 'sample_resumes', 'Alloys Support Engineer Resume.pdf', 'Alloys Product Solution Engineer Resume.pdf', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ensure the sample_resumes folder exists\n",
        "os.makedirs('sample_resumes', exist_ok=True)\n",
        "\n",
        "# List files in the current directory\n",
        "current_files = os.listdir()\n",
        "\n",
        "# Move PDF files from the current directory to sample_resumes folder\n",
        "for file in current_files:\n",
        "    if file.lower().endswith('.pdf'):\n",
        "        old_path = file\n",
        "        new_path = os.path.join('sample_resumes', file)\n",
        "        os.rename(old_path, new_path)\n",
        "        print(f\"Moved {file} to sample_resumes folder.\")\n",
        "\n",
        "# Verify that the PDFs are now in sample_resumes\n",
        "print(\"Files in 'sample_resumes':\", os.listdir('sample_resumes'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C1JZlnPxpdI",
        "outputId": "d0a3fcf5-22f2-488c-8f0d-e7a2688f4061"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved Alloys Support Engineer Resume.pdf to sample_resumes folder.\n",
            "Moved Alloys Product Solution Engineer Resume.pdf to sample_resumes folder.\n",
            "Files in 'sample_resumes': ['Alloys Support Engineer Resume.pdf', 'Alloys Product Solution Engineer Resume.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyFsYfPnyC8z",
        "outputId": "a3c95ef0-8d7d-40da-8903-e2ec46426d6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m4.9/5.6 MB\u001b[0m \u001b[31m142.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20240706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "import os\n",
        "\n",
        "# Define the directory containing your resumes\n",
        "resume_dir = 'sample_resumes'\n",
        "pdf_files = [file for file in os.listdir(resume_dir) if file.lower().endswith('.pdf')]\n",
        "\n",
        "# Loop through each PDF file and extract a text preview\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(resume_dir, pdf_file)\n",
        "    try:\n",
        "        text = extract_text(pdf_path)\n",
        "        print(f\"--- Preview of {pdf_file} ---\")\n",
        "        print(text[:500])  # Print the first 500 characters\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkMB-C7VyKjz",
        "outputId": "918cbe84-5ca2-4549-e81b-1b974b534334"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Preview of Alloys Support Engineer Resume.pdf ---\n",
            "Alloys Obiero Omullo \n",
            "Email: omulloalloys212@gmail.com | Phone: +254742336253 \n",
            "LinkedIn: https://www.linkedin.com/in/alloys-omullo-2a9148204/ \n",
            "Portfolio: https://engineering-portfolio-sh-3k2dy1m.gamma.site/ \n",
            "Location: Nairobi, Kenya \n",
            "\n",
            "Professional Summary \n",
            "\n",
            "Experienced Support Engineer with expertise in Finacle Core Banking support, system \n",
            "customization, API integration, and ETL data migration. Skilled in SQL, Oracle \n",
            "database administration, UNIX/Linux environments, and DevOps practices. Prove\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- Preview of Alloys Product Solution Engineer Resume.pdf ---\n",
            "Alloys Obiero Omullo \n",
            "Email: omulloalloys212@gmail.com | Phone: +254742336253 \n",
            "LinkedIn: https://www.linkedin.com/in/alloys-omullo-2a9148204/ \n",
            "Portfolio: https://engineering-portfolio-sh-3k2dy1m.gamma.site/ \n",
            "Location: Nairobi, Kenya \n",
            "\n",
            "Professional Summary \n",
            "\n",
            "Innovative Product Solution Engineer with a strong background in technical training, \n",
            "product support, and renewable energy solutions. Adept at pre-sales technical \n",
            "discussions, after-sales support, and product adaptation to meet market deman\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Replace multiple spaces and newlines with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove any leading or trailing whitespace\n",
        "    return text.strip()\n",
        "\n",
        "# Create a dictionary to store the cleaned text for each resume\n",
        "cleaned_texts = {}\n",
        "\n",
        "# Process each PDF file again to clean its content\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(resume_dir, pdf_file)\n",
        "    try:\n",
        "        # Extract the text using pdfminer.six\n",
        "        raw_text = extract_text(pdf_path)\n",
        "        # Clean the text using our function\n",
        "        cleaned_texts[pdf_file] = clean_text(raw_text)\n",
        "        print(f\"Cleaned text preview for {pdf_file}:\")\n",
        "        print(cleaned_texts[pdf_file][:500])  # Print first 500 characters of the cleaned text\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELx6qY9kybGJ",
        "outputId": "1e8edb65-c42a-43a4-b516-4063a5eb59a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text preview for Alloys Support Engineer Resume.pdf:\n",
            "Alloys Obiero Omullo Email: omulloalloys212@gmail.com | Phone: +254742336253 LinkedIn: https://www.linkedin.com/in/alloys-omullo-2a9148204/ Portfolio: https://engineering-portfolio-sh-3k2dy1m.gamma.site/ Location: Nairobi, Kenya Professional Summary Experienced Support Engineer with expertise in Finacle Core Banking support, system customization, API integration, and ETL data migration. Skilled in SQL, Oracle database administration, UNIX/Linux environments, and DevOps practices. Proven ability \n",
            "\n",
            "==================================================\n",
            "\n",
            "Cleaned text preview for Alloys Product Solution Engineer Resume.pdf:\n",
            "Alloys Obiero Omullo Email: omulloalloys212@gmail.com | Phone: +254742336253 LinkedIn: https://www.linkedin.com/in/alloys-omullo-2a9148204/ Portfolio: https://engineering-portfolio-sh-3k2dy1m.gamma.site/ Location: Nairobi, Kenya Professional Summary Innovative Product Solution Engineer with a strong background in technical training, product support, and renewable energy solutions. Adept at pre-sales technical discussions, after-sales support, and product adaptation to meet market demands. Experi\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('cleaned_resumes.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(cleaned_texts, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"Cleaned resume data saved to 'cleaned_resumes.json'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8awkBiSynS8",
        "outputId": "ec508e1b-6d5c-483a-f98c-a3286d8fe50e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned resume data saved to 'cleaned_resumes.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example annotation for two resumes (adjust the details according to your actual content)\n",
        "annotations = {\n",
        "    \"Alloys Support Engineer Resume.pdf\": {\n",
        "        \"contact\": {\n",
        "            \"name\": \"Alloys Obiero Omullo\",\n",
        "            \"email\": \"omulloalloys212@gmail.com\",\n",
        "            \"phone\": \"+254742336253\",\n",
        "            \"linkedin\": \"https://www.linkedin.com/in/alloys-omullo-2a9148204/\",\n",
        "            \"portfolio\": \"https://engineering-portfolio-sh-3k2dy1m.gamma.site/\",\n",
        "            \"location\": \"Nairobi, Kenya\"\n",
        "        },\n",
        "        \"education\": \"B.Sc. in Information Technology from XYZ University (Year – Year)\",\n",
        "        \"work_experience\": \"Experience with Finacle Core Banking support, system customization, API integration, and ETL data migration.\",\n",
        "        \"skills\": [\"SQL\", \"Oracle\", \"UNIX/Linux\", \"DevOps\"],\n",
        "        \"projects\": \"Developed support systems for banking solutions and conducted system optimizations.\"\n",
        "    },\n",
        "    \"Alloys Product Solution Engineer Resume.pdf\": {\n",
        "        \"contact\": {\n",
        "            \"name\": \"Alloys Obiero Omullo\",\n",
        "            \"email\": \"omulloalloys212@gmail.com\",\n",
        "            \"phone\": \"+254742336253\",\n",
        "            \"linkedin\": \"https://www.linkedin.com/in/alloys-omullo-2a9148204/\",\n",
        "            \"portfolio\": \"https://engineering-portfolio-sh-3k2dy1m.gamma.site/\",\n",
        "            \"location\": \"Nairobi, Kenya\"\n",
        "        },\n",
        "        \"education\": \"B.Sc. in Electrical Engineering from ABC University (Year – Year)\",\n",
        "        \"work_experience\": \"Specialized in technical training, product support, and renewable energy solutions.\",\n",
        "        \"skills\": [\"Technical Training\", \"Product Support\", \"Renewable Energy\"],\n",
        "        \"projects\": \"Led initiatives to enhance product adaptation and supported pre- and post-sales technical discussions.\"\n",
        "    }\n",
        "    # Add annotations for the remaining resumes similarly...\n",
        "}\n",
        "\n",
        "# Save the annotations to a JSON file for future use\n",
        "import json\n",
        "\n",
        "with open('annotated_resumes.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(annotations, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"Annotations saved to 'annotated_resumes.json'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh7-voqlzHZE",
        "outputId": "6e146817-b232-4c18-a788-68ff6f67ba85"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations saved to 'annotated_resumes.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_email(text):\n",
        "    # Simple regex for matching emails\n",
        "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "    emails = re.findall(email_pattern, text)\n",
        "    return emails[0] if emails else None\n",
        "\n",
        "# Test on a cleaned resume text\n",
        "sample_text = cleaned_texts[\"Alloys Support Engineer Resume.pdf\"]\n",
        "email = extract_email(sample_text)\n",
        "print(\"Extracted Email:\", email)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5rCy4ofzuTz",
        "outputId": "d31de4a4-5df3-4b9f-d76c-3c7318307fb8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Email: omulloalloys212@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.training import Example\n",
        "\n",
        "# Create a blank English model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Add the NER component using its string name\n",
        "if \"ner\" not in nlp.pipe_names:\n",
        "    nlp.add_pipe(\"ner\", last=True)\n",
        "\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Example training data: list of (text, annotations) tuples\n",
        "TRAIN_DATA = [\n",
        "    (\n",
        "        \"Alloys Obiero Omullo Email: omulloalloys212@gmail.com Phone: +254742336253\",\n",
        "        {\"entities\": [(0, 20, \"CONTACT_NAME\"),\n",
        "                      (27, 56, \"EMAIL\"),\n",
        "                      (64, 78, \"PHONE\")]}\n",
        "    ),\n",
        "    # Add additional training examples as needed\n",
        "]\n",
        "\n",
        "# Add labels from training data to the NER component\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for start, end, label in annotations.get(\"entities\"):\n",
        "        ner.add_label(label)\n",
        "\n",
        "# Convert training data to Example objects\n",
        "examples = []\n",
        "for text, annot in TRAIN_DATA:\n",
        "    doc = nlp.make_doc(text)\n",
        "    example = Example.from_dict(doc, annot)\n",
        "    examples.append(example)\n",
        "\n",
        "# Begin training\n",
        "optimizer = nlp.begin_training()\n",
        "n_iter = 100  # Number of training iterations\n",
        "\n",
        "for itn in range(n_iter):\n",
        "    random.shuffle(examples)\n",
        "    losses = {}\n",
        "    batches = minibatch(examples, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        nlp.update(batch, drop=0.35, sgd=optimizer, losses=losses)\n",
        "    print(f\"Iteration {itn+1} Losses:\", losses)\n",
        "\n",
        "# Save the trained model\n",
        "nlp.to_disk(\"resume_ner_model\")\n",
        "print(\"Custom NER model saved to 'resume_ner_model'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERdoVzT11Dww",
        "outputId": "290bc879-0e99-40f1-f470-78d1260d78dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Alloys Obiero Omullo Email: omulloalloys212@gmail....\" with entities \"[(0, 20, 'CONTACT_NAME'), (27, 56, 'EMAIL'), (64, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 Losses: {'ner': 5.892856627702713}\n",
            "Iteration 2 Losses: {'ner': 5.792671039700508}\n",
            "Iteration 3 Losses: {'ner': 5.670697074383497}\n",
            "Iteration 4 Losses: {'ner': 5.5677271373569965}\n",
            "Iteration 5 Losses: {'ner': 5.4036957286298275}\n",
            "Iteration 6 Losses: {'ner': 5.260887686163187}\n",
            "Iteration 7 Losses: {'ner': 4.854232173413038}\n",
            "Iteration 8 Losses: {'ner': 4.762515407055616}\n",
            "Iteration 9 Losses: {'ner': 4.239803832024336}\n",
            "Iteration 10 Losses: {'ner': 3.698271594941616}\n",
            "Iteration 11 Losses: {'ner': 3.527267901226878}\n",
            "Iteration 12 Losses: {'ner': 2.9349398463964462}\n",
            "Iteration 13 Losses: {'ner': 2.4405425214208663}\n",
            "Iteration 14 Losses: {'ner': 2.3130670748651028}\n",
            "Iteration 15 Losses: {'ner': 1.7723939949646592}\n",
            "Iteration 16 Losses: {'ner': 1.30751683562994}\n",
            "Iteration 17 Losses: {'ner': 1.564152680854022}\n",
            "Iteration 18 Losses: {'ner': 1.6591708638734417}\n",
            "Iteration 19 Losses: {'ner': 1.4949328655220597}\n",
            "Iteration 20 Losses: {'ner': 1.082538783093696}\n",
            "Iteration 21 Losses: {'ner': 1.1997224862275289}\n",
            "Iteration 22 Losses: {'ner': 0.8047264320920533}\n",
            "Iteration 23 Losses: {'ner': 13.354072391986847}\n",
            "Iteration 24 Losses: {'ner': 2.3042448989954254}\n",
            "Iteration 25 Losses: {'ner': 12.214429900050163}\n",
            "Iteration 26 Losses: {'ner': 12.250675417482853}\n",
            "Iteration 27 Losses: {'ner': 11.031809076666832}\n",
            "Iteration 28 Losses: {'ner': 9.81404829211533}\n",
            "Iteration 29 Losses: {'ner': 9.789223769679666}\n",
            "Iteration 30 Losses: {'ner': 8.991741051897407}\n",
            "Iteration 31 Losses: {'ner': 7.5056119952350855}\n",
            "Iteration 32 Losses: {'ner': 3.4414920053095557}\n",
            "Iteration 33 Losses: {'ner': 5.038573066703975}\n",
            "Iteration 34 Losses: {'ner': 3.8671564660035074}\n",
            "Iteration 35 Losses: {'ner': 2.8093397269039997}\n",
            "Iteration 36 Losses: {'ner': 1.4361411613062955}\n",
            "Iteration 37 Losses: {'ner': 2.0464811362326145}\n",
            "Iteration 38 Losses: {'ner': 2.7504973709583282}\n",
            "Iteration 39 Losses: {'ner': 1.6884817029349506}\n",
            "Iteration 40 Losses: {'ner': 1.2795217990060337}\n",
            "Iteration 41 Losses: {'ner': 1.786535685765557}\n",
            "Iteration 42 Losses: {'ner': 0.9720805651850242}\n",
            "Iteration 43 Losses: {'ner': 0.7210403368612788}\n",
            "Iteration 44 Losses: {'ner': 0.9187206488568336}\n",
            "Iteration 45 Losses: {'ner': 0.7269074971089822}\n",
            "Iteration 46 Losses: {'ner': 0.5325915938270782}\n",
            "Iteration 47 Losses: {'ner': 0.6926609106594697}\n",
            "Iteration 48 Losses: {'ner': 0.4074448402679991}\n",
            "Iteration 49 Losses: {'ner': 0.29163093425268016}\n",
            "Iteration 50 Losses: {'ner': 0.23796832986681693}\n",
            "Iteration 51 Losses: {'ner': 0.09714232590067695}\n",
            "Iteration 52 Losses: {'ner': 0.1204831706703402}\n",
            "Iteration 53 Losses: {'ner': 0.09503697669529743}\n",
            "Iteration 54 Losses: {'ner': 0.05516558486590384}\n",
            "Iteration 55 Losses: {'ner': 0.05140349963826907}\n",
            "Iteration 56 Losses: {'ner': 0.007388108130214732}\n",
            "Iteration 57 Losses: {'ner': 0.002779756111507936}\n",
            "Iteration 58 Losses: {'ner': 0.0015481244641257774}\n",
            "Iteration 59 Losses: {'ner': 0.00015608035449887758}\n",
            "Iteration 60 Losses: {'ner': 0.0011477533143402496}\n",
            "Iteration 61 Losses: {'ner': 0.0001280486741579434}\n",
            "Iteration 62 Losses: {'ner': 8.771619479250314e-06}\n",
            "Iteration 63 Losses: {'ner': 8.429771771484296e-06}\n",
            "Iteration 64 Losses: {'ner': 6.351820472261238e-06}\n",
            "Iteration 65 Losses: {'ner': 1.3596541399596429e-05}\n",
            "Iteration 66 Losses: {'ner': 7.163321252753483e-06}\n",
            "Iteration 67 Losses: {'ner': 3.554216120475913e-06}\n",
            "Iteration 68 Losses: {'ner': 3.294654080110426e-08}\n",
            "Iteration 69 Losses: {'ner': 3.761040257962891e-06}\n",
            "Iteration 70 Losses: {'ner': 1.0413619348195909e-06}\n",
            "Iteration 71 Losses: {'ner': 3.153583636648872e-08}\n",
            "Iteration 72 Losses: {'ner': 1.9769675548950244e-08}\n",
            "Iteration 73 Losses: {'ner': 1.5015615170634218e-07}\n",
            "Iteration 74 Losses: {'ner': 6.039485306392675e-07}\n",
            "Iteration 75 Losses: {'ner': 5.910079488492424e-09}\n",
            "Iteration 76 Losses: {'ner': 1.5642256378004503e-07}\n",
            "Iteration 77 Losses: {'ner': 1.3855138451745208e-08}\n",
            "Iteration 78 Losses: {'ner': 4.4758421650231434e-08}\n",
            "Iteration 79 Losses: {'ner': 7.120274531199734e-09}\n",
            "Iteration 80 Losses: {'ner': 2.5385678554933354e-08}\n",
            "Iteration 81 Losses: {'ner': 7.030947017381358e-08}\n",
            "Iteration 82 Losses: {'ner': 9.315799821493515e-09}\n",
            "Iteration 83 Losses: {'ner': 1.7006225453630198e-07}\n",
            "Iteration 84 Losses: {'ner': 9.668820144771332e-10}\n",
            "Iteration 85 Losses: {'ner': 4.992468553574868e-10}\n",
            "Iteration 86 Losses: {'ner': 5.905664306153065e-09}\n",
            "Iteration 87 Losses: {'ner': 1.0745152863147805e-08}\n",
            "Iteration 88 Losses: {'ner': 3.0540458489337685e-08}\n",
            "Iteration 89 Losses: {'ner': 8.981313980744463e-08}\n",
            "Iteration 90 Losses: {'ner': 1.0877469339525195e-08}\n",
            "Iteration 91 Losses: {'ner': 1.135286688443996e-09}\n",
            "Iteration 92 Losses: {'ner': 1.6556408578791027e-08}\n",
            "Iteration 93 Losses: {'ner': 7.693363236843126e-09}\n",
            "Iteration 94 Losses: {'ner': 9.473344172647707e-10}\n",
            "Iteration 95 Losses: {'ner': 7.369632821961931e-11}\n",
            "Iteration 96 Losses: {'ner': 2.012436779700327e-09}\n",
            "Iteration 97 Losses: {'ner': 5.987595551692184e-08}\n",
            "Iteration 98 Losses: {'ner': 9.415721722525063e-10}\n",
            "Iteration 99 Losses: {'ner': 5.24821997452138e-09}\n",
            "Iteration 100 Losses: {'ner': 1.1731756557730462e-09}\n",
            "Custom NER model saved to 'resume_ner_model'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "    print(f\"Text: '{ent.text}' | Start: {ent.start_char} | End: {ent.end_char} | Label: {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJjAm9dB2GdL",
        "outputId": "f36865dd-a92c-437f-fd92-72cf94e93933"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'Alloys Obiero Omullo' | Start: 0 | End: 20 | Label: CONTACT_NAME\n",
            "Text: ', API integration,' | Start: 347 | End: 365 | Label: CONTACT_NAME\n",
            "Text: 'complex technical issues, optimize' | Start: 516 | End: 550 | Label: CONTACT_NAME\n",
            "Text: ', and ensure' | Start: 569 | End: 581 | Label: CONTACT_NAME\n",
            "Text: 'technical support.' | Start: 674 | End: 692 | Label: CONTACT_NAME\n",
            "Text: 'API Integration •' | Start: 788 | End: 805 | Label: CONTACT_NAME\n",
            "Text: '& Oracle Database' | Start: 810 | End: 827 | Label: CONTACT_NAME\n",
            "Text: '& Data Migration •' | Start: 876 | End: 894 | Label: CONTACT_NAME\n",
            "Text: 'Windows System Administration' | Start: 908 | End: 937 | Label: CONTACT_NAME\n",
            "Text: 'stability and' | Start: 1281 | End: 1294 | Label: CONTACT_NAME\n",
            "Text: 'Assisted in API' | Start: 1310 | End: 1325 | Label: CONTACT_NAME\n",
            "Text: 'Developed and maintained' | Start: 1407 | End: 1431 | Label: CONTACT_NAME\n",
            "Text: 'Automated routine tasks' | Start: 1513 | End: 1536 | Label: CONTACT_NAME\n",
            "Text: 'technical documentation,' | Start: 1623 | End: 1647 | Label: CONTACT_NAME\n",
            "Text: 'user manuals, and troubleshooting' | Start: 1648 | End: 1681 | Label: CONTACT_NAME\n",
            "Text: ', performing backup' | Start: 1802 | End: 1821 | Label: CONTACT_NAME\n",
            "Text: 'training and technical' | Start: 2050 | End: 2072 | Label: CONTACT_NAME\n",
            "Text: 'line technical support, diagnosing and' | Start: 2213 | End: 2251 | Label: CONTACT_NAME\n",
            "Text: 'system issues.' | Start: 2262 | End: 2276 | Label: CONTACT_NAME\n",
            "Text: 'Assisted in network' | Start: 2279 | End: 2298 | Label: CONTACT_NAME\n",
            "Text: 'troubleshooting and system' | Start: 2299 | End: 2325 | Label: CONTACT_NAME\n",
            "Text: 'enhance system integration and performance' | Start: 2398 | End: 2440 | Label: CONTACT_NAME\n",
            "Text: 'Data Protection Policies' | Start: 2939 | End: 2963 | Label: CONTACT_NAME\n",
            "Text: 'Incident Management' | Start: 2993 | End: 3012 | Label: CONTACT_NAME\n",
            "Text: 'Achievements • Optimized' | Start: 3045 | End: 3069 | Label: CONTACT_NAME\n",
            "Text: 'execution time by 30' | Start: 3115 | End: 3135 | Label: CONTACT_NAME\n",
            "Text: 'Automated Data Migration' | Start: 3140 | End: 3164 | Label: CONTACT_NAME\n",
            "Text: 'errors and ensuring' | Start: 3187 | End: 3206 | Label: CONTACT_NAME\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6sJ3YG3h2HL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}